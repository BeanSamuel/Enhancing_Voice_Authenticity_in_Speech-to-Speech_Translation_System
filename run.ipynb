{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6be89982-79a4-4152-8e07-b33d6c7c7b02",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 系統配置確認(建議使用GPU執行)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e06e885e-7c20-4238-b323-8bee319c8bbb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/llm/Jupyter_Lab/Samuel/NCU/資訊工程概論/VITS-fast-fine-tuning\n"
     ]
    }
   ],
   "source": [
    "%cd /home/llm/Jupyter_Lab/Samuel/NCU/資訊工程概論/VITS-fast-fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74a39682-0954-42fe-88a9-aa28cd553945",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jan  3 22:49:56 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4090        Off | 00000000:01:00.0 Off |                  Off |\n",
      "|  0%   38C    P8              18W / 450W |   8434MiB / 24564MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A    164985      C   ...niconda3/envs/jupyterlab/bin/python     8424MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0aa94f4c-4969-4e4a-b8b2-321d3636b22f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/llm/Jupyter_Lab/Samuel/NCU/資訊工程概論/VITS-fast-fine-tuning\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c23c794-27c2-4db3-8bdb-23d4c72adf7b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a900156-6373-448b-8ce6-2ef4673adb9e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "libcudart.so.12: cannot open shared object file: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchaudio\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mseamless_communication\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minference\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Translator\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mseamless_m4t_hf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlang_list\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      9\u001b[0m   LANGUAGE_NAME_TO_CODE,\n\u001b[1;32m     10\u001b[0m   S2ST_TARGET_LANGUAGE_NAMES,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m   TEXT_SOURCE_LANGUAGE_NAMES,\n\u001b[1;32m     14\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchaudio/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m      2\u001b[0m     _extension,\n\u001b[1;32m      3\u001b[0m     compliance,\n\u001b[1;32m      4\u001b[0m     datasets,\n\u001b[1;32m      5\u001b[0m     functional,\n\u001b[1;32m      6\u001b[0m     io,\n\u001b[1;32m      7\u001b[0m     kaldi_io,\n\u001b[1;32m      8\u001b[0m     models,\n\u001b[1;32m      9\u001b[0m     pipelines,\n\u001b[1;32m     10\u001b[0m     sox_effects,\n\u001b[1;32m     11\u001b[0m     transforms,\n\u001b[1;32m     12\u001b[0m     utils,\n\u001b[1;32m     13\u001b[0m )\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_backend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AudioMetaData  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchaudio/_extension/__init__.py:45\u001b[0m\n\u001b[1;32m     43\u001b[0m _IS_ALIGN_AVAILABLE \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _IS_TORCHAUDIO_EXT_AVAILABLE:\n\u001b[0;32m---> 45\u001b[0m     \u001b[43m_load_lib\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlibtorchaudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchaudio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_torchaudio\u001b[39;00m  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[1;32m     49\u001b[0m     _check_cuda_version()\n",
      "File \u001b[0;32m~/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torchaudio/_extension/utils.py:64\u001b[0m, in \u001b[0;36m_load_lib\u001b[0;34m(lib)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path\u001b[38;5;241m.\u001b[39mexists():\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_library\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m torch\u001b[38;5;241m.\u001b[39mclasses\u001b[38;5;241m.\u001b[39mload_library(path)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/torch/_ops.py:852\u001b[0m, in \u001b[0;36m_Ops.load_library\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    847\u001b[0m path \u001b[38;5;241m=\u001b[39m _utils_internal\u001b[38;5;241m.\u001b[39mresolve_library_path(path)\n\u001b[1;32m    848\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m dl_open_guard():\n\u001b[1;32m    849\u001b[0m     \u001b[38;5;66;03m# Import the shared library into the process, thus running its\u001b[39;00m\n\u001b[1;32m    850\u001b[0m     \u001b[38;5;66;03m# static (global) initialization code in order to register custom\u001b[39;00m\n\u001b[1;32m    851\u001b[0m     \u001b[38;5;66;03m# operators with the JIT.\u001b[39;00m\n\u001b[0;32m--> 852\u001b[0m     \u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCDLL\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloaded_libraries\u001b[38;5;241m.\u001b[39madd(path)\n",
      "File \u001b[0;32m~/miniconda3/envs/jupyterlab/lib/python3.11/ctypes/__init__.py:376\u001b[0m, in \u001b[0;36mCDLL.__init__\u001b[0;34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_FuncPtr \u001b[38;5;241m=\u001b[39m _FuncPtr\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 376\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m \u001b[43m_dlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    378\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m handle\n",
      "\u001b[0;31mOSError\u001b[0m: libcudart.so.12: cannot open shared object file: No such file or directory"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import Union\n",
    "import gradio as gr\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchaudio\n",
    "from seamless_communication.inference import Translator\n",
    "from seamless_m4t_hf.lang_list import (\n",
    "  LANGUAGE_NAME_TO_CODE,\n",
    "  S2ST_TARGET_LANGUAGE_NAMES,\n",
    "  S2TT_TARGET_LANGUAGE_NAMES,\n",
    "  T2TT_TARGET_LANGUAGE_NAMES,\n",
    "  TEXT_SOURCE_LANGUAGE_NAMES,\n",
    ")\n",
    "from IPython.display import Audio\n",
    "import librosa\n",
    "from pydub import AudioSegment\n",
    "import wave\n",
    "import soundfile as sf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6eb3851-8f1f-4c55-9daf-6276fbf4bed1",
   "metadata": {},
   "source": [
    "# Seamless m4t Setup\n",
    "**Translator Choices** : \"seamlessM4T_medium\" , \"seamlessM4T_large\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6966cb19-986b-4b0b-9009-88f4a6376ce6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Translator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 17\u001b[0m\n\u001b[1;32m     13\u001b[0m DEFAULT_TARGET_LANGUAGE \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFrench\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     15\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m translator \u001b[38;5;241m=\u001b[39m \u001b[43mTranslator\u001b[49m(\n\u001b[1;32m     18\u001b[0m   model_name_or_card\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseamlessM4T_large\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     19\u001b[0m   vocoder_name_or_card\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvocoder_36langs\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     20\u001b[0m   device\u001b[38;5;241m=\u001b[39mdevice,\n\u001b[1;32m     21\u001b[0m   dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     22\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Translator' is not defined"
     ]
    }
   ],
   "source": [
    "CACHE_EXAMPLES = os.getenv(\"CACHE_EXAMPLES\") == \"1\"\n",
    "\n",
    "TASK_NAMES = [\n",
    "  \"S2ST (Speech to Speech translation)\",\n",
    "  \"S2TT (Speech to Text translation)\",\n",
    "  \"T2ST (Text to Speech translation)\",\n",
    "  \"T2TT (Text to Text translation)\",\n",
    "  \"ASR (Automatic Speech Recognition)\",\n",
    "]\n",
    "\n",
    "AUDIO_SAMPLE_RATE = 16000.0\n",
    "MAX_INPUT_AUDIO_LENGTH = 60  # in seconds\n",
    "DEFAULT_TARGET_LANGUAGE = \"French\"\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "translator = Translator(\n",
    "  model_name_or_card=\"seamlessM4T_large\",\n",
    "  vocoder_name_or_card=\"vocoder_36langs\",\n",
    "  device=device,\n",
    "  dtype=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf913d51-d2ab-4294-bb6d-fc1854f4b19e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(\n",
    "    task_name: str,\n",
    "    audio_source: str,\n",
    "    input_audio_mic: Union[str, None],\n",
    "    input_audio_file: Union[str, None],\n",
    "    input_text: Union[str, None],\n",
    "    source_language: Union[str, None],\n",
    "    target_language: str,\n",
    ") -> tuple[Union[tuple[int, np.ndarray], None], str]:\n",
    "    task_name = task_name.split()[0]\n",
    "    source_language_code = LANGUAGE_NAME_TO_CODE.get(source_language, None)\n",
    "    target_language_code = LANGUAGE_NAME_TO_CODE[target_language]\n",
    "\n",
    "    if task_name in [\"S2ST\", \"S2TT\", \"ASR\"]:\n",
    "        if audio_source == \"microphone\":\n",
    "            input_data = input_audio_mic\n",
    "        else:\n",
    "            input_data = input_audio_file\n",
    "\n",
    "        arr, org_sr = torchaudio.load(input_data)\n",
    "        new_arr = torchaudio.functional.resample(arr, orig_freq=org_sr, new_freq=AUDIO_SAMPLE_RATE)\n",
    "        max_length = int(MAX_INPUT_AUDIO_LENGTH * AUDIO_SAMPLE_RATE)\n",
    "        if new_arr.shape[1] > max_length:\n",
    "            new_arr = new_arr[:, :max_length]\n",
    "            gr.Warning(f\"Input audio is too long. Only the first {MAX_INPUT_AUDIO_LENGTH} seconds is used.\")\n",
    "        torchaudio.save(input_data, new_arr, sample_rate=int(AUDIO_SAMPLE_RATE))\n",
    "    else:\n",
    "        input_data = input_text\n",
    "    text_out, batchedspeechoutput = translator.predict(\n",
    "        input=input_data,\n",
    "        task_str=task_name,\n",
    "        tgt_lang=target_language_code,\n",
    "        src_lang=source_language_code,\n",
    "    )\n",
    "    if task_name in [\"S2ST\", \"T2ST\"]:\n",
    "        return (batchedspeechoutput.sample_rate, batchedspeechoutput.audio_wavs[0][0][0].cpu().detach().numpy()), text_out\n",
    "    else:\n",
    "        return None, text_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e62e27f-b566-49ef-b302-f300b3ec8060",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_s2tt(input_audio_file: str, source_language:str, target_language: str) -> tuple[str, str, str]:\n",
    "    return predict(\n",
    "        task_name=\"S2TT\",\n",
    "        audio_source=\"file\",\n",
    "        input_audio_mic=None,\n",
    "        input_audio_file=input_audio_file,\n",
    "        input_text=None,\n",
    "        source_language=source_language,\n",
    "        target_language=target_language,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce47d17-bad7-4bef-abf9-f07fed8c668f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_text = process_s2tt(input_audio_file='./seamless_m4t_hf/assets/sample_input.wav',source_language='English',target_language='Mandarin Chinese')\n",
    "print('Translated Text:',test_text[1][0],sep='\\n')\n",
    "print('Tranlated Audio:')\n",
    "Audio('./seamless_m4t_hf/assets/sample_input.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e196b7-1caa-4e4f-84d8-e981cb8a03a1",
   "metadata": {},
   "source": [
    "# VITS-fast-fine-tuning Interface Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e76769-3451-4915-b796-4261a2b1e830",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%cd VITS-fast-fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13e49e0-02c6-4147-871b-86390fc92f00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import no_grad, LongTensor\n",
    "import argparse\n",
    "import commons\n",
    "from mel_processing import spectrogram_torch\n",
    "import utils\n",
    "from models import SynthesizerTrn\n",
    "import gradio as gr\n",
    "import librosa\n",
    "import webbrowser\n",
    "\n",
    "from text import text_to_sequence, _clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55212a1-ba00-44a6-91fc-5b57fc953a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "language_marks = {\n",
    "    \"Japanese\": \"\",\n",
    "    \"日本語\": \"[JA]\",\n",
    "    \"简体中文\": \"[ZH]\",\n",
    "    \"English\": \"[EN]\",\n",
    "    \"Mix\": \"\",\n",
    "}\n",
    "# lang = ['日本語', '简体中文', 'English', 'Mix']\n",
    "lang = ['简体中文']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a9d3eb5-89d0-4967-af88-62a63e08425c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_as_wav(filepath, sr, audio_data):\n",
    "    with wave.open(filepath, 'w') as wav_file:\n",
    "        wav_file.setnchannels(1)\n",
    "        wav_file.setsampwidth(2)\n",
    "        wav_file.setframerate(sr)\n",
    "        wav_file.writeframes(np.int16(audio_data).tobytes())\n",
    "        print(f'Saved at {filepath}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a238057b-0ba4-4af3-ae59-3cc5cc0868d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(text, hps, is_symbol):\n",
    "    text_norm = text_to_sequence(text, hps.symbols, [] if is_symbol else hps.data.text_cleaners)\n",
    "    if hps.data.add_blank:\n",
    "        text_norm = commons.intersperse(text_norm, 0)\n",
    "    text_norm = LongTensor(text_norm)\n",
    "    return text_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26df0721-0515-4c61-9a39-beeb5697e954",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tts_fn(model, hps, speaker_ids):\n",
    "    def tts_fn(text, speaker, language, speed):\n",
    "        speaker_id = speaker_ids[speaker]\n",
    "        stn_tst = get_text(text, hps, False)\n",
    "        with no_grad():\n",
    "            x_tst = stn_tst.unsqueeze(0).to(device)\n",
    "            x_tst_lengths = LongTensor([stn_tst.size(0)]).to(device)\n",
    "            sid = LongTensor([speaker_id]).to(device)\n",
    "            audio = model.infer(x_tst, x_tst_lengths, sid=sid, noise_scale=.667, noise_scale_w=0.8,\n",
    "                                length_scale=1.0 / speed)[0][0, 0].data.cpu().float().numpy()\n",
    "        del stn_tst, x_tst, x_tst_lengths, sid\n",
    "        return \"Success\", (hps.data.sampling_rate, audio)\n",
    "\n",
    "    return tts_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5153096-273d-4483-98e9-3699dc2a0eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vc_fn(model, hps, speaker_ids):\n",
    "    def vc_fn(original_speaker, record_audio):\n",
    "        input_audio = record_audio\n",
    "        sampling_rate, audio = input_audio\n",
    "        sf.write(\"./raw_audio/output.wav\", audio, sampling_rate)\n",
    "        \n",
    "        output_text = process_s2tt(input_audio_file='./raw_audio/output.wav',source_language='English',target_language='Mandarin Chinese')\n",
    "        ouptut_text = str(output_text[1][0])\n",
    "\n",
    "        speaker_id = speaker_ids[original_speaker]\n",
    "        stn_tst = get_text(ouptut_text, hps, False)\n",
    "        with no_grad():\n",
    "            x_tst = stn_tst.unsqueeze(0).to(device)\n",
    "            x_tst_lengths = LongTensor([stn_tst.size(0)]).to(device)\n",
    "            sid = LongTensor([speaker_id]).to(device)\n",
    "            audio = model.infer(x_tst, x_tst_lengths, sid=sid, noise_scale=.667, noise_scale_w=0.8,\n",
    "                                length_scale=1.0)[0][0, 0].data.cpu().float().numpy()\n",
    "        del stn_tst, x_tst, x_tst_lengths, sid\n",
    "        return \"Success\", (hps.data.sampling_rate, audio)\n",
    "\n",
    "    return vc_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22dec24e-7534-4442-8418-7a47cb2be074",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'utils' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m hps \u001b[38;5;241m=\u001b[39m \u001b[43mutils\u001b[49m\u001b[38;5;241m.\u001b[39mget_hparams_from_file(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./fine_tune_models/finetune_speaker.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m net_g \u001b[38;5;241m=\u001b[39m SynthesizerTrn(\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mlen\u001b[39m(hps\u001b[38;5;241m.\u001b[39msymbols),\n\u001b[1;32m      5\u001b[0m     hps\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfilter_length \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m      6\u001b[0m     hps\u001b[38;5;241m.\u001b[39mtrain\u001b[38;5;241m.\u001b[39msegment_size \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m hps\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mhop_length,\n\u001b[1;32m      7\u001b[0m     n_speakers\u001b[38;5;241m=\u001b[39mhps\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mn_speakers,\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhps\u001b[38;5;241m.\u001b[39mmodel)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      9\u001b[0m _ \u001b[38;5;241m=\u001b[39m net_g\u001b[38;5;241m.\u001b[39meval()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'utils' is not defined"
     ]
    }
   ],
   "source": [
    "hps = utils.get_hparams_from_file(\"./fine_tune_models/finetune_speaker.json\")\n",
    "\n",
    "net_g = SynthesizerTrn(\n",
    "    len(hps.symbols),\n",
    "    hps.data.filter_length // 2 + 1,\n",
    "    hps.train.segment_size // hps.data.hop_length,\n",
    "    n_speakers=hps.data.n_speakers,\n",
    "    **hps.model).to(device)\n",
    "_ = net_g.eval()\n",
    "\n",
    "_ = utils.load_checkpoint(\"./fine_tune_models/G_latest.pth\", net_g, None)\n",
    "speaker_ids = hps.speakers\n",
    "speakers = list(hps.speakers.keys())\n",
    "tts_fn = create_tts_fn(net_g, hps, speaker_ids)\n",
    "vc_fn = create_vc_fn(net_g, hps, speaker_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17265db-c89b-4c28-b68f-90fad64044df",
   "metadata": {},
   "source": [
    "# Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9cfc3065-dd65-4d75-b8b2-bb25ef647fde",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'speakers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 10\u001b[0m\n\u001b[1;32m      6\u001b[0m textbox \u001b[38;5;241m=\u001b[39m gr\u001b[38;5;241m.\u001b[39mTextArea(label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mText\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      7\u001b[0m                       placeholder\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mType your sentence here\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      8\u001b[0m                       value\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m你好 這是測試。\u001b[39m\u001b[38;5;124m\"\u001b[39m, elem_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtts-input\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# select character\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m char_dropdown \u001b[38;5;241m=\u001b[39m gr\u001b[38;5;241m.\u001b[39mDropdown(choices\u001b[38;5;241m=\u001b[39m\u001b[43mspeakers\u001b[49m, value\u001b[38;5;241m=\u001b[39mspeakers[\u001b[38;5;241m0\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcharacter\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     11\u001b[0m language_dropdown \u001b[38;5;241m=\u001b[39m gr\u001b[38;5;241m.\u001b[39mDropdown(choices\u001b[38;5;241m=\u001b[39mlang, value\u001b[38;5;241m=\u001b[39mlang[\u001b[38;5;241m0\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlanguage\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     12\u001b[0m duration_slider \u001b[38;5;241m=\u001b[39m gr\u001b[38;5;241m.\u001b[39mSlider(minimum\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, maximum\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, step\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m,\n\u001b[1;32m     13\u001b[0m                             label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m速度 Speed\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'speakers' is not defined"
     ]
    }
   ],
   "source": [
    "app = gr.Blocks()\n",
    "with app:\n",
    "    with gr.Tab(\"Text-to-Speech\"):\n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                textbox = gr.TextArea(label=\"Text\",\n",
    "                                      placeholder=\"Type your sentence here\",\n",
    "                                      value=\"你好 這是測試。\", elem_id=f\"tts-input\")\n",
    "                # select character\n",
    "                char_dropdown = gr.Dropdown(choices=speakers, value=speakers[0], label='character')\n",
    "                language_dropdown = gr.Dropdown(choices=lang, value=lang[0], label='language')\n",
    "                duration_slider = gr.Slider(minimum=0.1, maximum=5, value=1, step=0.1,\n",
    "                                            label='速度 Speed')\n",
    "            with gr.Column():\n",
    "                text_output = gr.Textbox(label=\"Message\")\n",
    "                audio_output = gr.Audio(label=\"Output Audio\", elem_id=\"tts-audio\")\n",
    "                btn = gr.Button(\"Generate!\")\n",
    "                btn.click(tts_fn,\n",
    "                          inputs=[textbox, char_dropdown, language_dropdown, duration_slider,],\n",
    "                          outputs=[text_output, audio_output])\n",
    "    with gr.Tab(\"Voice Conversion\"):\n",
    "        gr.Markdown(\"\"\"\n",
    "                        錄製你的聲音，並挑選欲轉換的音色。User代表的音色是你自己。\n",
    "        \"\"\")\n",
    "        with gr.Column():\n",
    "            record_audio = gr.Audio(label=\"record your voice\", source=\"microphone\")\n",
    "            source_speaker = gr.Dropdown(choices=speakers, value=\"User\", label=\"user\")\n",
    "        with gr.Column():\n",
    "            message_box = gr.Textbox(label=\"Message\")\n",
    "            converted_audio = gr.Audio(label='converted audio')\n",
    "        btn = gr.Button(\"Convert!\")\n",
    "\n",
    "        btn.click(vc_fn, inputs=[source_speaker, record_audio],\n",
    "                  outputs=[message_box, converted_audio])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0dfcf282-ce88-4861-8b8b-6fa5a0cdf7eb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'webbrowser' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mwebbrowser\u001b[49m\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp://127.0.0.1:7860\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'webbrowser' is not defined"
     ]
    }
   ],
   "source": [
    "webbrowser.open(\"http://127.0.0.1:7860\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3378f23e-4661-46e8-aa33-126036e5ef73",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "Running on public URL: https://fbdcabc38b2bb19048.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://fbdcabc38b2bb19048.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "2023-12-29 23:21:25,921 DEBUG -- jieba: Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "2023-12-29 23:21:25,924 DEBUG -- jieba: Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.355 seconds.\n",
      "2023-12-29 23:21:26,279 DEBUG -- jieba: Loading model cost 0.355 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "2023-12-29 23:21:26,280 DEBUG -- jieba: Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ㄋㄧˇㄏㄠˇ  ㄓㄜˋㄕˋ ㄘㄜˋㄕˋ。\n",
      " length:20\n",
      " length:20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/llm/miniconda3/envs/jupyterlab/lib/python3.11/site-packages/gradio/processing_utils.py:183: UserWarning: Trying to convert audio automatically from float32 to 16-bit int format.\n",
      "  warnings.warn(warning.format(data.dtype))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ㄓㄠˋ ㄩㄣˊㄈㄟˉ。\n",
      " length:11\n",
      " length:11\n"
     ]
    }
   ],
   "source": [
    "app.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c00fcaa-f117-4a24-9b2d-b63d94eaea12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "autoscrollcelloutput": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
